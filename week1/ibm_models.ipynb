{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP2 project 1: Lexical Alignment\n",
    "###  Kai Liang, Yijie Zhang, Billy Chan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import operator\n",
    "import aer\n",
    "from collections import *\n",
    "from decimal import *\n",
    "from aer import read_naacl_alignments\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English sentences in training set: 231164\n",
      "Number of French sentences in training set: 231164\n",
      "Number of English sentences in validation set: 37\n",
      "Number of French sentences in validation set: 37\n",
      "Number of English sentences in testing set: 447\n",
      "Number of French sentences in testing set: 447\n"
     ]
    }
   ],
   "source": [
    "# reading training data\n",
    "en_train = open('./training/hansards.36.2.e', mode='r', encoding='utf-8').read().splitlines() # utf-8 encoding\n",
    "fr_train = open('./training/hansards.36.2.f', mode='r', encoding='utf-8').read().splitlines() # utf-8 encoding\n",
    "\n",
    "# reading validation data\n",
    "en_val = open('./validation/dev.e', mode='r', encoding='utf-8').read().splitlines() # utf-8 encoding\n",
    "fr_val = open('./validation/dev.f', mode='r', encoding='utf-8').read().splitlines() # utf-8 encoding\n",
    "\n",
    "# reading test data\n",
    "en_test = open('./testing/test/test.e', mode='r', encoding='utf-8').read().splitlines() # utf-8 encoding\n",
    "fr_test = open('./testing/test/test.f', mode='r', encoding='utf-8').read().splitlines() # utf-8 encoding\n",
    "\n",
    "# path of gold standrad\n",
    "path = 'validation/dev.wa.nonullalign'\n",
    "\n",
    "print('Number of English sentences in training set:', len(en_train))\n",
    "print('Number of French sentences in training set:', len(fr_train))\n",
    "print('Number of English sentences in validation set:', len(en_val))\n",
    "print('Number of French sentences in validation set:', len(fr_val))\n",
    "print('Number of English sentences in testing set:', len(en_test))\n",
    "print('Number of French sentences in testing set:', len(fr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first English sentence: 36 th Parliament , 2 nd Session \n"
     ]
    }
   ],
   "source": [
    "print('The first English sentence:', en_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first French sentence: 36 e Législature , 2 ième Session \n"
     ]
    }
   ],
   "source": [
    "print('The first French sentence:', fr_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = np.load('theta_0.npy').item()\n",
    "# theta_10 = np.load('theta_10.npy').item()\n",
    "# count_f_e_0 = np.load('count_f_e_0.npy').item()\n",
    "# count_e_0 = np.load('count_e_0.npy').item()\n",
    "\n",
    "# '''\n",
    "# np.save('theta_0.npy', theta_0) \n",
    "# np.save('count_f_e_0.npy', count_f_e) \n",
    "# np.save('count_e_0.npy', count_e)\n",
    "# np.save('theta_10.npy', theta) \n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split sentence into words\n",
    "def preprocess(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess training data, validation data and testing data\n",
    "for i in range(len(en_train)):\n",
    "    en_train[i] = preprocess(en_train[i])\n",
    "    en_train[i] = ['NULLINDICATOR'] + en_train[i]\n",
    "    fr_train[i] = preprocess(fr_train[i])\n",
    "for i in range(len(en_val)):\n",
    "    en_val[i] = preprocess(en_val[i])\n",
    "    fr_val[i] = preprocess(fr_val[i])\n",
    "for i in range(len(en_test)):\n",
    "    en_test[i] = preprocess(en_test[i])\n",
    "    fr_test[i] = preprocess(fr_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessed training example sentence: ['36', 'e', 'Législature', ',', '2', 'ième', 'Session']\n",
      "Proccessed validation example sentence: ['chacun', 'en', 'lui', '-', 'même', 'est', 'très', 'complexe', 'et', 'le', 'lien', 'entre', 'les', 'deux', 'le', 'est', 'encore', 'davantage', 'de', 'sorte', 'que', 'pour', 'beaucoup', 'la', 'situation', 'présente', 'est', 'confuse', '.']\n",
      "Proccessed testing example sentence: ['2', '.']\n"
     ]
    }
   ],
   "source": [
    "print('Proccessed training example sentence:', fr_train[0])\n",
    "print('Proccessed validation example sentence:', fr_val[0])\n",
    "print('Proccessed testing example sentence:', fr_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Log-likelihood Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loglikelihood(en_train, fr_train, theta):\n",
    "    N = len(en_train)\n",
    "    loglikelihood_total = 0\n",
    "    for n in range(N): # for all pairs of sentences\n",
    "        \n",
    "        cleaned_en_n = en_train[n]\n",
    "        len_en_n = len(cleaned_en_n)\n",
    "        \n",
    "        cleaned_fr_n = fr_train[n]\n",
    "        len_fr_n = len(cleaned_fr_n)\n",
    "        \n",
    "        loglikelihood_n = np.log(len_fr_n/len_en_n) + len_fr_n*np.log(1/(len_en_n+1))\n",
    "        for fr_word in cleaned_fr_n: # every french word\n",
    "            # find the english word that maximize p(fr/en) \n",
    "            max_p_fe = 0\n",
    "            for en_word in cleaned_en_n:\n",
    "                p_fe = theta[en_word][fr_word]\n",
    "                if p_fe > max_p_fe:\n",
    "                    max_p_fe = p_fe\n",
    "            \n",
    "            loglikelihood_n += np.log(float(max_p_fe))\n",
    "        loglikelihood_total += loglikelihood_n\n",
    "    return loglikelihood_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Compute AER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aer(en_data, fr_data, theta):\n",
    "    # compute AER score for the given data\n",
    "    predictions = []\n",
    "    for s in range(len(en_data)):\n",
    "        alignments=[]\n",
    "        l_e = len(en_data[s])\n",
    "        l_f = len(fr_data[s])\n",
    "        for i in range(l_f):\n",
    "            vals = []\n",
    "            for j in range(l_e):\n",
    "                vals.append(theta[en_data[s][j]][fr_data[s][i]])\n",
    "            max_idx = vals.index(max(vals))\n",
    "            alignments.append((max_idx+1, i+1))\n",
    "        predictions.append(set(alignments))\n",
    "    gold_sets = read_naacl_alignments(path)\n",
    "    metric = aer.AERSufficientStatistics()\n",
    "    for gold, pred in zip(gold_sets, predictions):\n",
    "        metric.update(sure=gold[0], probable=gold[1], predicted=pred)\n",
    "    # AER\n",
    "    return metric.aer(), predictions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Export NAACL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_naacl(predictions, filename):\n",
    "    with open('{}.naacl'.format(filename), 'w') as file:\n",
    "        for index, sen in enumerate(predictions):\n",
    "            for aligns in sen:\n",
    "                for align in aligns:\n",
    "                    file.write('{} {} {} S\\n'.format(index+1, align[0], align[1]))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * IBM1 - Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_1():\n",
    "    return Decimal(0)\n",
    "\n",
    "def init_2():\n",
    "    return defaultdict(init_1)\n",
    "\n",
    "def init_theta(en_train, fr_train):\n",
    "    # initialize theta\n",
    "    theta = defaultdict(init_2)\n",
    "    N = len(en_train)\n",
    "    for n in range(N):\n",
    "        cleaned_en_n = en_train[n]\n",
    "        cleaned_fr_n = fr_train[n]     \n",
    "        for j_en_word in cleaned_en_n:\n",
    "            for i_fr_word in cleaned_fr_n:\n",
    "                theta[j_en_word][i_fr_word] = 0      \n",
    "    for en_word in theta:\n",
    "        count = len(theta[en_word])\n",
    "        for fr_word in theta[en_word]:\n",
    "            theta[en_word][fr_word] = Decimal(1 / count)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English words in the training set: 36636\n"
     ]
    }
   ],
   "source": [
    "theta = init_theta(en_train, fr_train)\n",
    "print('Number of English words in the training set:', len(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * IBM1 - update via EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_EM(en_train, fr_train, theta, en_val, fr_val, en_test, fr_test, K):\n",
    "    N = len(en_train)\n",
    "    AER = []\n",
    "    iteration = []\n",
    "    t_log = []\n",
    "    for k in range(K):\n",
    "        iteration.append(k+1)\n",
    "        print('Iteration {}:'.format(k))\n",
    "        count_f_e = defaultdict(init_1)\n",
    "        total_f = defaultdict(init_1)\n",
    "        for n in range(N):\n",
    "            cleaned_en_n = en_train[n]\n",
    "            cleaned_fr_n = fr_train[n]\n",
    "            count_e = defaultdict(lambda: Decimal(0))\n",
    "            for j in range(len(cleaned_en_n)):\n",
    "                for i in range(len(cleaned_fr_n)):\n",
    "                    count_e[cleaned_en_n[j]] += Decimal(theta[cleaned_en_n[j]][cleaned_fr_n[i]])\n",
    "            for j in range(len(cleaned_en_n)):\n",
    "                for i in range(len(cleaned_fr_n)):\n",
    "                    f_e = (cleaned_fr_n[i], cleaned_en_n[j])\n",
    "                    count_f_e[f_e] += Decimal(theta[cleaned_en_n[j]][cleaned_fr_n[i]] / count_e[cleaned_en_n[j]])\n",
    "                    total_f[cleaned_fr_n[i]] += Decimal(theta[cleaned_en_n[j]][cleaned_fr_n[i]] / count_e[cleaned_en_n[j]])\n",
    "        for n in range(N):\n",
    "            cleaned_en_n = en_train[n]\n",
    "            cleaned_fr_n = fr_train[n]\n",
    "            for en in cleaned_en_n:\n",
    "                for fr in cleaned_fr_n:\n",
    "                    theta[en][fr] = Decimal(count_f_e[(fr, en)] / total_f[fr])\n",
    "        # compute AER on the validation set\n",
    "        aer, _ = compute_aer(en_val, fr_val, theta)\n",
    "        print('Validation AER:', aer)\n",
    "        AER.append(aer)\n",
    "        \n",
    "        log_likelihood = get_loglikelihood(en_train, fr_train, theta)\n",
    "        t_log.append(log_likelihood)\n",
    "        print(\"Training log-likelihood\", log_likelihood)\n",
    "        \n",
    "    aer_test, test_alignment = compute_aer(en_test, fr_test, theta)\n",
    "    print('Test AER:', aer_test)\n",
    "    export_naacl(test_alignment, 'ibm1.mle')\n",
    "    print('File saved successfully.')\n",
    "    np.save(\"theta_10.npy\", theta)\n",
    "    return theta, AER, t_log, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:\n",
      "Validation AER: 0.8508026440037771\n",
      "Training log-likelihood -28094857.93114429\n",
      "Iteration 1:\n"
     ]
    }
   ],
   "source": [
    "theta_10, AER, t_log, iteration = train_EM(en_train, fr_train, theta, en_val, fr_val, en_test, fr_test, K=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration, AER, figsize=(10,5))\n",
    "xlabel('Iteration')\n",
    "ylabel('AER')\n",
    "plt.show()\n",
    "savefig('AER-IBM1.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration, t_log, figsize=(10,5))\n",
    "xlabel('Iteration')\n",
    "ylabel('Log-likelihood')\n",
    "plt.show()\n",
    "savefig('LogLikelihood-IBM1.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * IBM2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starts here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
